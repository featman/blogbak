title: 复习笔记-操作系统  
date: 2015-5-17 19:11:44
categories: 操作系统
tags: [复习笔记,操作系统,linux,进程线程] 
---
- 进程管理
- 内存管理
- 文件管理
- 设备管理
<!--more-->

#### [linux复习推荐博客](http://blog.csdn.net/zjf280441589 )

### 一.进程管理
#### 1.进程分为五种状态：就绪、运行、等待、暂停、僵死。
进程调度实际上是就绪和运行的来回切换。等待状态是进程在等待IO操作完成，这时系统就会给等待的进程一个中断，使之释放cpu变为等待状态。暂停状态与等待状态类似。僵死状态是因为进程运行结束，释放了除PCB之外的所有资源。
#### 2.PCB，进程控制块。
进程调度和进程控制实际上靠的就是PCB来标识的。系统每创建新的进程，就会创建一个PCB，这个PCB分为两部分，一部分放在内核栈中，可以理解为一个指针，另一部分放在用户进程栈中。
它包括：
控制信息：记录了当前的状态，调度策略，优先级，时间片。
现场信息：时间片用完后，要把目前的现场状态记录下来，简单说就是把当前cpu的寄存器值存储起来。以便下次调度的时候，cpu能够迅速找到上次的地方。
其他资源：进程的地址空间，文件系统等。
#### 3.系统调用
实际上是一个从用户态-》内核态-》用户态的过程。
#### 4.进程控制。
进程控制就是管理进程的其他几种状态的转换，当然这个过程不包括就绪--------运行的转换。跟PCB关系密切。比如创建进程，销毁进程，阻塞进程，唤醒进程。
#### 5.进程调度常见的算法
（这些算法都是综合使用的，没有只用其中的一种）
FIFO，时间片轮转法（这个过程包括时间片和优先级的综合使用），普通调度算法（与时间片轮转法类似，只不过时间片耗尽完之后，要放到过期队列中）
#### 6.进程通信
> 管道：同步的，一个进程做为输入端，另一个进程作为输出端，中间用管道传送，相关函数为系统调用pipe().在linux下ps x|grep ping 就是一个典型的进程间通信的例子。  

> 信号量：同步的，其实信号量更多的是解决两个进程间的同步问题，两个进程同时访问一块内存的数据时，这时候要采取一些措施对这块内存保护，p,v就是解决这个问题的。s为信号量。p为-，v为+
> sem_wait(&sem); 临界区；sem_post(&sem);

> 
> 信号：linux系统下由很多都是由信号作为通信的标志，比如kill pid
> 
> 消息队列：与管道类似，只不过这个是异步的。传递的信息多。

> 套接字：socket套接字利用了网络通信的port，实际上用127.0.0.1的两个端口就可以相互之间传送数据，此时并没有通过网络出去，而是在进程间传送数据。

> 共享内存：见9


——————
> ##### 常见的IPC通信原理图：

![image description](http://7xkz95.com1.z0.glb.clouddn.com/15-8-11/77923111.jpg)
> ##### 共享内存通信原理图如下：

![image description](http://7xkz95.com1.z0.glb.clouddn.com/15-8-11/48069999.jpg)

#### 7.进程与线程的比较
在创建线程和销毁线程的过程中，系统开销比进程要小的多。
线程可以充分利用多核CPU的优势。因为无论有几核的cpu，只能有一个进程被调入cpu运行，线程则不同。
多个线程共享同一内存地址空间，所以线程间的通信要简单的多，也安全的多。

#### 8.线程同步的方式（unix网络编程：进程间通信 127-188页）
- 条件变量
- 互斥锁（pthread_mutex_lock,pthread_mutex_unlock）：临界区锁上，不允许读写。
- 信号量(sem_wait，sem_post)：有名信号量更多用于进程间通信，无名信号量更多用于线程间通信。
- 读写锁：在临界区被锁上，只有读可以。临界区没有被锁上，则读写都可以。比互斥锁并发性强。

##### 条件变量，互斥锁，信号量区别
(截图在unix网络编程：进程间通信 178页)
![image description](http://7xkz95.com1.z0.glb.clouddn.com/15-8-11/59197613.jpg)
#### 9.共享内存【同步的、需要配合有名信号量使用】
> **（ 动态库实际上就是很多个进程都共同享有，它存在于同一块物理内存中，如math.so）**： 共享内存是进程间通信中最简单的方式之一。
共享内存允许两个或更多进程访问同一块内存，就如同 malloc() 函数向不同进程返回了指向同一个物理内存区域的指针。当一个进程改变了这块地址中的内容的时候，其它进程都会察觉到这个更改。
> 共享内存效率高，并不需要内核去做中转。
> 由于没有内核的管理，所以多进程同时访问的这块内存的同步工作就由用户自己去完成，这时候可以采用信号量进行同步。
> 共享内存段到最大限制为32M。它本身存在于物理内存中，每个进程都可以访问的到，在用户的进程空间中，位于堆和zhan之间到部分，可以称为内存共享映射区。

### 二.内存管理
linux内存分布图：
![image description](http://7xkz95.com1.z0.glb.clouddn.com/15-8-11/84552973.jpg)
- 上图是进程的虚拟地址空间，每个进程都有。通过页面与物理内存对应，物理内存到位置和存储情况无法获知，只有内核知道。
- 栈在高地址位置，并从高往下增长栈空间，最大默认为8MB
- 堆在内存到低地址处，从低往高增长，最大为3G。
- 中间到为共享内存或者动态库到存储区域。最大默认为32MB。

![image description](http://7xkz95.com1.z0.glb.clouddn.com/15-8-11/37937918.jpg)
上图与linux内存分布图相比少了地址到走向正好相反。这张是C/C++的内存分布图。
#### 1.包括：内存的分配和回收、地址空间转换、存储空间的保护、内存的扩容。
http://blog.chinaunix.net/uid-27052262-id-3237894.html
#### 2.地址空间转换：
其实我们应用程序用的内存都是逻辑地址，并不是真正的物理内存地址。这样做的目的是为了提高内存使用率。虚拟地址->物理地址，这个过程是靠内存管理模块（操作系统提供的分页技术）和硬件单元（MMU）共同完成的。
#### 3.分页技术
逻辑地址高20位为页号，低12位为空间内偏移量。页帧为物理地址中的一页。操作系统采用页表来构建页号与页帧的映射关系。
转换过程：讲逻辑地址分成页号和页内偏移量，再用页号为检索去页表中查找对应的页帧，再用MMU去换算成真正的物理地址，cpu根据此地址进行内存寻址，然后运算。
#### 4.内存扩容（虚拟内存）
缘何存在：由于现在的应用程序内存占用较大，所以单纯靠物理内存来提供寻址显然不够。虚拟内存就是为了解决物理内存不足的问题。
现在的程序运行，cpu在一个时间段内只访问程序的一部分，并不是全部，所以调入到内存中的好多内存空间都不会再短期内使用，这时候需要把这一部分内存放入到速度稍微慢一些的外存上，使内存空间增大一些。虚拟内存技术就是这样的条件下诞生的。这块内存区域也叫交换分区。
过程应该是：进程调入到内存中，有很多不用的内存将会放入到虚拟内存中。当要访问的页面对应的页帧并没有在页表中标识为有效时，这时候MMU就会发出一个缺页中断，CPU接收到中断后，阻塞原进程，然后进入中断处理程序把swap分区缺页信息调入到内存中，并修改相应的页表，此时中断处理程序结束，cpu开始执行原进程。
#### 5.FIFO 和LRU算法
参考:

http://baike.baidu.com/link?url=V6QOR5RFyL7r952PDCnpscF0A9e6a3shpx9Vkf41WGjzeHA3jY0nZtX0i0Av4CjvPFNBPfdNIMuKyG6VCQkKKq

  
http://flychao88.iteye.com/blog/1977653


http://yinzhezq.blog.163.com/blog/static/1648628902010112961039187/

首先说缺页请求：
缺页是说进程要操作某块内存的时候，就会进行压入队列的操作，他会检查现有的页面是不是存在，如果不存在，那么就发出缺页中断，这时候要么直接插入到内存块中，要么从虚拟内存中拿出。

LRU算法：需要一个队列，这个队列做了一些策略，就是把那些之后立刻又用到的内存页面 再换到对尾的位置。


FIFO算法：同样需要一个队列，与LRU不同的是，如果内存块中有这个页面，并不置换顺序。

#### 6.内存泄漏
也称作“存储渗漏”

用动态存储分配函数动态开辟的空间，在使用完毕后未释放，结果导致一直占据该内存单元。直到程序结束。即所谓内存泄漏。
### 三.文件管理
- 1.FCB 文件控制块
类似于PCB，每个文件都有一个FCB，FCB块在EXT3中目前有两个部分组成，一个是目录项（存储文件名和索引值，这个为次部），另一个是索引节点（这个是主部，包含除文件名之外的所有信息）。
- 2.文件系统层次
由上到下：虚拟文件系统--------磁盘文件系统映射层（实际文件系统）---------通用块层--------驱动-----------磁盘
除了最后一个，前边的这几个都是内核去操作和管理的。
 VFS：【它为用户进程和内核提供一个使用的统一接口。为用户隐藏不同文件系统的差异。】收到系统调用请求，利用实际文件系统和IO来处理请求，然后返回结果。 通用块层：为内核隐藏不同的硬件差异。提供统一的接口去操作硬件

### 四.设备管理 
- 1.关键技术：中断技术、缓冲与缓存技术、DMA技术
- 2.缓冲技术
> 为了解决设备和CPU之间传输速度不匹配的问题。cpu的速度相当快，而大多数的IO设备速度较慢，这样传输的过程中，cpu总是在等待设备的IO。对cpu来说造成了浪费，同时其他进程也分配不到cpu，效率低下。
> 这时候进程控制程序会把等待IO完成的进程设置为等待状态。具体过程如下：当进程要输出给设备的时候，cpu把需要的数据传送给“缓冲区”，由于缓冲区在内存中，速度也很快，传送完之后，进程接着干其他事情。至于真正发送给设备是靠内核去做，把缓冲区的数据发送给设备。当进程要读设备数据的时候，也是同理，先是告诉内核要读设备，然后内核就从设备中读数据到缓冲区，读好之后把缓冲区的数据拷贝到用户空间，这时候用户进程就可以读了。【内核管理的，应用进程触碰不到的。】
- 3.缓存技术 
> 为了解决cpu频繁访问设备的次数。比如cpu总是要访问一个设备，每次访问设备，都要去读设备，这样总体来说还是很慢，如果设备把常用的数据放在缓存区，由于缓存区的速度和内存是一样的，这样读取速度就提高了。

- 4.DMA 为了减少外设与内存的通信依赖cpu的次数。
